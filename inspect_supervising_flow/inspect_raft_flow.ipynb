{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../loaders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raft import RAFTExhaustiveDataset\n",
    "from config import config_parser\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "import imageio\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "def save_video(frames, out_path):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            frames: list of np.ndarray of shape (H, W, 3) and dtype np.uint8\n",
    "    \"\"\"\n",
    "    try:\n",
    "        imageio.mimwrite(out_path, frames, quality=8, fps=10)\n",
    "\n",
    "        print(f'ðŸ’¾ Saved video to {out_path}')\n",
    "    except Exception as e:\n",
    "        print(f'ðŸ’¾âš ï¸ Failed to save video to {out_path}')\n",
    "        print(e)\n",
    "        print(f'frames[0].shape: {frames[0].shape}, frames[0].dtype: {frames[0].dtype}')\n",
    "\n",
    "def save_flow_as_video(out_path, flows):\n",
    "    flow_imgs = [visualize_flow_as_arrows(flow_map) for flow_map in tqdm(flows, \"converting flows to images\")]\n",
    "\n",
    "    save_video(flow_imgs, out_path)\n",
    "\n",
    "    return flow_imgs\n",
    "\n",
    "def count_map_to_image(count_maps, i):\n",
    "\n",
    "    # expand pixel value into 3 dimensions\n",
    "    count_map = np.repeat(count_maps[i][:, :, np.newaxis], 3, axis=2)\n",
    "\n",
    "    # normalize across all count maps\n",
    "    count_map = count_map / np.max(count_maps)\n",
    "    \n",
    "    # convert to np.uint8\n",
    "    count_map = (count_map * 255).astype(np.uint8)\n",
    "\n",
    "    return count_map\n",
    "\n",
    "def draw_text(frames, text, location):\n",
    "    \"\"\" Returns array of frames with text drawn on them \"\"\"\n",
    "    for i in range(len(frames)):\n",
    "        frames[i] = cv2.putText(frames[i], text, location, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    return frames\n",
    "def concat_frames(frames1, frames2, left_label=None, right_label=None):\n",
    "    \"\"\" Returns array of side-by-side frames of shape (N, H, W*2, 3) \"\"\"\n",
    "    concatted = np.concatenate([frames1, frames2], axis=2)\n",
    "\n",
    "    if left_label is not None:\n",
    "        concatted = draw_text(concatted, left_label, (10, 50))\n",
    "\n",
    "    if right_label is not None:\n",
    "        concatted = draw_text(concatted, right_label, (concatted.shape[2]//2 + 10, 50))\n",
    "    \n",
    "    return concatted\n",
    "\n",
    "def save_json(out_path, data):\n",
    "    \"\"\" Saves data to json file \"\"\"\n",
    "    with open(out_path, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    print(f'ðŸ’¾ Saved json to {out_path}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "\n",
    "class PreprocessingInspector():\n",
    "    def __init__(self, seq_name, data_dir):\n",
    "        self.seq_name = seq_name\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "        self.flow_dir = os.path.join(DATA_DIR, 'raft_exhaustive')\n",
    "        self.flow_mask_dir = os.path.join(DATA_DIR, 'raft_masks')\n",
    "        self.img_dir = os.path.join(DATA_DIR, 'color')\n",
    "        self.img_names = sorted(os.listdir(self.img_dir))\n",
    "    \n",
    "\n",
    "    def visualize_count_maps(self, out_dir=None):\n",
    "        if out_dir is None:\n",
    "            out_dir = os.path.join(self.seq_name, 'count_maps')\n",
    "        \n",
    "        count_dir = os.path.join(DATA_DIR, 'count_maps')\n",
    "        count_img_names = sorted(os.listdir(count_dir))\n",
    "\n",
    "        count_maps = [imageio.imread(os.path.join(count_dir, img_name)) for img_name in tqdm(count_img_names, desc=\"Loading count maps\")]\n",
    "        count_images = [count_map_to_image(count_maps, i) for i in tqdm(range(len(count_maps)), desc=\"Converting count maps to images\")]\n",
    "\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        save_video(count_images, os.path.join(out_dir, 'count_maps.mp4'))\n",
    "    \n",
    "    def _load_flow_maps(frame_interval, load_masks=True, load_flows=True):\n",
    "        flows_raw = []\n",
    "        flows_masks = []\n",
    "\n",
    "        for i in tqdm(range(0, len(self.img_names)-frame_interval), desc='Loading flow maps'):\n",
    "            img_name1 = self.img_names[i]\n",
    "            img_name2 = self.img_names[i+frame_interval]\n",
    "\n",
    "            if load_flows:\n",
    "                # get flow for this pair of frames\n",
    "                flow_file = os.path.join(self.flow_dir, '{}_{}.npy'.format(img_name1, img_name2))\n",
    "                flow = np.load(flow_file)\n",
    "                flows_raw.append(flow)\n",
    "\n",
    "            if load_masks:\n",
    "                # get mask for this pair of frames\n",
    "                mask_file = os.path.join(self.flow_mask_dir, '{}_{}.png'.format(img_name1, img_name2))\n",
    "                masks = imageio.imread(mask_file) / 255.\n",
    "\n",
    "                cycle_consistency_mask = masks[..., 0] > 0\n",
    "                occlusion_mask = masks[..., 1] > 0\n",
    "\n",
    "                mask = cycle_consistency_mask | occlusion_mask\n",
    "\n",
    "                if mask.sum() == 0:\n",
    "                    invalid = True\n",
    "                    mask = np.ones_like(cycle_consistency_mask)\n",
    "                else:\n",
    "                    invalid = False\n",
    "                \n",
    "                flows_masks.append(mask)\n",
    "        \n",
    "        return flows_raw, flows_masks\n",
    "    def visualize_raft_flows(self, out_dir=None, frame_interval=1):\n",
    "        \n",
    "        flows_raw, flows_masks = self._load_flow_maps(frame_interval)\n",
    "        if out_dir is None:\n",
    "            out_dir = os.path.join(self.seq_name, 'flows')\n",
    "\n",
    "        stats = {\n",
    "            'kept_correspondences': int(sum([mask.sum() for mask in flows_masks])),\n",
    "            'total_correspondences': int(sum([mask.shape[0] * mask.shape[1] for mask in flows_masks])),\n",
    "        }\n",
    "        stats['percentage_kept'] = stats['kept_correspondences'] / stats['total_correspondences']\n",
    "        print(stats)\n",
    "        save_json(os.path.join(out_dir, f'stats_frame_interval={frame_interval}.json'), stats)\n",
    "        \n",
    "        print(f\"Across the entire video, kept {stats['kept_correspondences']} out of {stats['total_correspondences']} pixel-to-pixel correspondences ({stats['percentage_kept'] * 100}%)\")\n",
    "        flows_filtered = [flow * mask[..., np.newaxis] for flow, mask in zip(flows_raw, flows_masks)]\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        flows_raw_img = save_flow_as_video(os.path.join(out_dir, f'flow_unfiltered_frame_interval={frame_interval}.mp4'), flows_raw)\n",
    "        flows_filtered_img = save_flow_as_video(os.path.join(out_dir, f'flow_filtered_frame_interval={frame_interval}.mp4'), flows_filtered)\n",
    "\n",
    "        flows_side_by_side = concat_frames(np.array(flows_raw_img), np.array(flows_filtered_img), left_label='Unfiltered', right_label='Filtered')\n",
    "        save_video(flows_side_by_side, os.path.join(out_dir, f'flow_side_by_side_frame_interval={frame_interval}.mp4'))\n",
    "\n",
    "        masks_imgs = [count_map_to_image(flows_masks, i) for i in range(len(flows_masks))]\n",
    "        save_video(masks_imgs, os.path.join(out_dir, f'masks_frame_interval={frame_interval}.mp4'))\n",
    "\n",
    "    def plot_filtering_percentage_across_frame_intervals(self, frame_intervals=[1, 2, 4, 8, 16, 32]):\n",
    "        results = []\n",
    "        for frame_interval in tqdm(frame_intervals, desc=f\"Computing stats for {len(frame_intervals)} frame intervals\"):\n",
    "            _, flows_masks = self._load_flow_maps(frame_interval, load_masks=True, load_flows=False)\n",
    "            stats = {\n",
    "                'kept_correspondences': int(sum([mask.sum() for mask in flows_masks])),\n",
    "                'total_correspondences': int(sum([mask.shape[0] * mask.shape[1] for mask in flows_masks])),\n",
    "            }\n",
    "            stats['percentage_kept'] = stats['kept_correspondences'] / stats['total_correspondences']\n",
    "\n",
    "            results.append({\n",
    "                'frame_interval': frame_interval,\n",
    "                **stats\n",
    "            })\n",
    "\n",
    "\n",
    "        # Sorting results by frame_interval for plotting\n",
    "        results.sort(key=lambda x: x['frame_interval'])\n",
    "\n",
    "        # Extracting values for plotting\n",
    "        x_values = [result['frame_interval'] for result in results]\n",
    "        y_values = [result['percentage_kept'] for result in results]\n",
    "\n",
    "        # Plotting the bar chart\n",
    "        plt.bar(x_values, y_values, color='blue')\n",
    "        plt.xlabel('Frame Intervals')\n",
    "        plt.ylabel('Percentage Kept (%)')\n",
    "        plt.title('Filtering Percentage across Frame Intervals')\n",
    "        plt.xticks(x_values)  # This sets the tick marks on x-axis based on the frame intervals\n",
    "        plt.grid(axis='y')\n",
    "\n",
    "        # Displaying the chart\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_NAME = \"soccer_short\"\n",
    "DATA_DIR = os.path.join(\"../omnimotion_videos/\", SEQ_NAME)\n",
    "\n",
    "inspector = PreprocessingInspector(SEQ_NAME, DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspector.visualize_raft_flows(frame_interval=10)\n",
    "inspector.visualize_count_maps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_flow_as_arrows(flow_uv, stride=10):\n",
    "    \"\"\"\n",
    "    Expects a two-dimensional flow image of shape.\n",
    "\n",
    "    Args:\n",
    "        flow_uv (np.ndarray): Flow UV image of shape [H,W,2]\n",
    "        stride (int): The step size between arrows, for both height and width.\n",
    "\n",
    "    Displays:\n",
    "        A matplotlib figure with arrows representing the flow at each grid point.\n",
    "    \"\"\"\n",
    "    assert flow_uv.ndim == 3, 'input flow must have three dimensions'\n",
    "    assert flow_uv.shape[-1] == 2, 'input flow must have shape [H,W,2]'\n",
    "    \n",
    "    H, W, _ = flow_uv.shape\n",
    "    \n",
    "    x = np.arange(0, W, stride)\n",
    "    y = np.arange(0, H, stride)\n",
    "    \n",
    "    x, y = np.meshgrid(x, y)\n",
    "    \n",
    "    u = flow_uv[::stride, ::stride, 0]\n",
    "    v = flow_uv[::stride, ::stride, 1]\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.quiver(x, y, u, v, angles='xy', scale_units='xy', scale=1, color='r')\n",
    "    plt.gca().invert_yaxis()  # To align the visualization with image coordinate system\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnimotion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
